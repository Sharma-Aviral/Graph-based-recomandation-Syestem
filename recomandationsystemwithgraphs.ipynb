{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "\n",
    "users = pd.read_csv('u.user', sep='|', header = None, encoding='latin-1',\n",
    "                    names=['userId','alter','geschlecht', 'beruf','PLZ'])\n",
    "\n",
    "movies = pd.read_csv('u.item', sep='|', header = None,encoding='latin-1', \n",
    "                     names=['itemId','title','veröffentlichung', 'NaN',\n",
    "                            'links', 'unknown','action', 'adventure', 'animation',\n",
    "                            'childrens','comedy', 'crime', 'documentary',\n",
    "                            'drama', 'fantasy', 'filmnoir', 'horror', 'musical',\n",
    "                            'mystery', 'romance', 'scifi', 'thriller', 'war',\n",
    "                            'western']) \n",
    "genre = pd.read_csv('u.genre', sep='|', header = None,encoding='latin-1',\n",
    "                    names=['genre', 'genreZahl'])\n",
    "\n",
    "trainset = pd.read_csv('ua.base', sep='\\t', header = None,\n",
    "                       names=['userId', 'itemId', 'rating', 'timestamp']) \n",
    "\n",
    "testset = pd.read_csv('ua.test', sep='\\t', header = None, \n",
    "                      names=['userId', 'itemId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainset['timestamp']\n",
    "del testset['timestamp']\n",
    "del users['PLZ']\n",
    "del movies['title']\n",
    "del movies['veröffentlichung']\n",
    "del movies['NaN']\n",
    "del movies['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ueberschussTests = list(set(testset['itemId']).difference(set(trainset['itemId'])))\n",
    "i = 0\n",
    "while i< len(ueberschussTests):  \n",
    "    index = list(testset['itemId']).index(ueberschussTests[i]) \n",
    "    testset = testset.drop([index])\n",
    "    i = i+1\n",
    "\n",
    "\n",
    "ueberschussMovies = list(set(movies['itemId']).difference(set(trainset['itemId'])))\n",
    "i = 0\n",
    "while i< len(ueberschussMovies):  \n",
    "    index = list(movies['itemId']).index(ueberschussMovies[i])\n",
    "    movies = movies.drop([index]) \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTensor(list, bool): \n",
    "\n",
    "    if bool:\n",
    "        list = torch.LongTensor(list.astype('category')\n",
    "                                .cat.codes.values) \n",
    "    else:\n",
    "        list = torch.LongTensor(list.values)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = buildTensor(trainset['userId'], True)\n",
    "itemId = buildTensor(trainset['itemId'], True)\n",
    "\n",
    "\n",
    "userIdTest = buildTensor(testset['userId'], True)\n",
    "itemIdTest = buildTensor(testset['itemId'], True)\n",
    "\n",
    "\n",
    "graph = dgl.heterograph({\n",
    "    ('user', 'rated', 'item'): (userId, itemId),\n",
    "\n",
    "    ('item', 'rated-by', 'user'): (itemId, userId)\n",
    "})\n",
    " \n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userAlter = buildTensor(users['alter'] // 10, False) \n",
    "userGeschlecht = buildTensor(users['geschlecht'], True)\n",
    "userBeruf = buildTensor(users['beruf'], True)\n",
    "\n",
    "\n",
    "moviesTypen = movies[['unknown','action', 'adventure', 'animation',\n",
    "        'childrens','comedy', 'crime', 'documentary',\n",
    "        'drama', 'fantasy', 'filmnoir', 'horror', \n",
    "        'musical', 'mystery', 'romance', 'scifi', \n",
    "        'thriller', 'war', 'western']].values\n",
    "\n",
    "\n",
    "userAlterNum = len(set(users['alter']//10))\n",
    "userGeschlechtNum = len(set(users['geschlecht']))\n",
    "userBerufNum = len(set(users['beruf']))\n",
    "moviesTypenNum = len(genre['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes['user'].data['alter'] = userAlter\n",
    "graph.nodes['user'].data['geschlecht'] = userGeschlecht\n",
    "graph.nodes['user'].data['beruf'] = userBeruf\n",
    "\n",
    "graph.nodes['item'].data['filmTyp'] = torch.FloatTensor(moviesTypen)\n",
    "\n",
    "\n",
    "bewertungen = buildTensor(trainset['rating'], False)\n",
    "bewertungenTest = buildTensor(testset['rating'], False)\n",
    "graph.edges['rated'].data['rating'] = bewertungen\n",
    "graph.edges['rated-by'].data['rating'] = bewertungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorTrainset = TensorDataset(userId, itemId, bewertungen)\n",
    "tensorTestset = TensorDataset(userIdTest, itemIdTest, bewertungenTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchSampler(object):\n",
    "\n",
    "    def __init__(self, graph, num_layers):\n",
    "        self.graph = graph\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "\n",
    "    def sample(self, batch):\n",
    "        users, items, ratings = zip(*batch)\n",
    "        users = torch.stack(users)\n",
    "        items = torch.stack(items)\n",
    "        ratings = torch.stack(ratings)\n",
    "        \n",
    "        pair_graph = dgl.heterograph(\n",
    "            {('user', 'rated', 'item'): (users, items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        \n",
    "\n",
    "        pair_graph = dgl.compact_graphs(pair_graph) \n",
    "        pair_graph.edata['rating'] = ratings \n",
    "        \n",
    "        # Konstruiere Blocks\n",
    "        seeds = {'user': pair_graph.nodes['user'].data[dgl.NID],\n",
    "                 'item': pair_graph.nodes['item'].data[dgl.NID]}\n",
    "        blocks = self.construct_blocks(seeds, (users, items)) \n",
    "        \n",
    "        for feature_name in self.graph.nodes['user'].data.keys():\n",
    "            blocks[0].srcnodes['user'].data[feature_name] = \\\n",
    "                self.graph.nodes['user'].data[feature_name][blocks[0].srcnodes['user'].data[dgl.NID]] \n",
    "            \n",
    "        for feature_name in self.graph.nodes['item'].data.keys():\n",
    "            blocks[0].srcnodes['item'].data[feature_name] = \\\n",
    "                self.graph.nodes['item'].data[feature_name][blocks[0].srcnodes['item'].data[dgl.NID]]\n",
    "\n",
    "        return pair_graph, blocks \n",
    "\n",
    "    def construct_blocks(self, seeds, user_item_pairs_to_remove):\n",
    "        blocks = []\n",
    "        users, items = user_item_pairs_to_remove\n",
    "        for i in range(self.num_layers):\n",
    "            \n",
    "\n",
    "            sampled_graph = dgl.in_subgraph(self.graph, seeds) \n",
    "            \n",
    "            sampled_eids = sampled_graph.edges['rated'].data[dgl.EID]\n",
    "            sampled_eids_rev = sampled_graph.edges['rated-by'].data[dgl.EID]\n",
    "            \n",
    "            \n",
    "            _, _, edges_to_remove = sampled_graph.edge_ids(users, items, etype='rated', return_uv=True)  \n",
    "            _, _, edges_to_remove_rev = sampled_graph.edge_ids(items, users, etype='rated-by', return_uv=True)\n",
    "            \n",
    "            sampled_with_edges_removed = sampled_graph\n",
    "            if len(edges_to_remove) > 0:\n",
    "                sampled_with_edges_removed = dgl.remove_edges(\n",
    "                    sampled_with_edges_removed, edges_to_remove, 'rated')\n",
    "                sampled_eids = sampled_eids[sampled_with_edges_removed.edges['rated'].data[dgl.EID]]\n",
    "            if len(edges_to_remove_rev) > 0:\n",
    "                sampled_with_edges_removed = dgl.remove_edges(\n",
    "                    sampled_with_edges_removed, edges_to_remove_rev, 'rated-by')\n",
    "                sampled_eids_rev = sampled_eids_rev[sampled_with_edges_removed.edges['rated-by'].data[dgl.EID]]\n",
    "           \n",
    "            block = dgl.to_block(sampled_with_edges_removed, seeds)\n",
    "            blocks.insert(0, block)\n",
    "            seeds = {'user': block.srcnodes['user'].data[dgl.NID],\n",
    "                     'item': block.srcnodes['item'].data[dgl.NID]}\n",
    "            \n",
    "            \n",
    "            block.edges['rated'].data['rating'] = \\\n",
    "                self.graph.edges['rated'].data['rating'][sampled_eids]\n",
    "            block.edges['rated-by'].data['rating'] = \\\n",
    "                self.graph.edges['rated-by'].data['rating'][sampled_eids_rev]\n",
    "            \n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "class GCMCConv(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.W_r = nn.Parameter(torch.randn(num_ratings + 1, hidden_dims, hidden_dims))\n",
    "        self.W_i = nn.Linear(hidden_dims * 2, hidden_dims)\n",
    "        \n",
    "    def compute_message(self, W, edges): \n",
    "        W_r = W[edges.data['rating']] \n",
    "        h = edges.src['h'] \n",
    "        m = (W_r @ h.unsqueeze(-1)).squeeze(2)\n",
    "        return m\n",
    "\n",
    "    def forward(self, graph, node_features):\n",
    "        with graph.local_scope():\n",
    "            src_features, dst_features = node_features\n",
    "            \n",
    "       \n",
    "            graph.srcdata['h'] = src_features \n",
    "            graph.dstdata['h'] = dst_features \n",
    "            \n",
    "\n",
    "            graph.apply_edges(lambda edges: {'m': self.compute_message(self.W_r, edges)})\n",
    "\n",
    "            graph.update_all(fn.copy_e('m', 'm'), fn.mean('m', 'h_neigh')) \n",
    "\n",
    "            result = F.relu(self.W_i(torch.cat([graph.dstdata['h'], graph.dstdata['h_neigh']], 1))) \n",
    "            return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "        self.heteroconv = dglnn.HeteroGraphConv(\n",
    "            {'rated': GCMCConv(hidden_dims, num_ratings), 'rated-by': GCMCConv(hidden_dims, num_ratings)},\n",
    "            aggregate='sum')\n",
    "                \n",
    "    def forward(self, block, input_user_features, input_item_features):\n",
    "        with block.local_scope():\n",
    "         \n",
    "            h_user = input_user_features \n",
    "            h_item = input_item_features\n",
    "            \n",
    "            \n",
    "            src_features = {'user': h_user, 'item': h_item} \n",
    "            dst_features = {'user': h_user[:block.number_of_dst_nodes('user')],\n",
    "                          \n",
    "                            'item': h_item[:block.number_of_dst_nodes('item')]} \n",
    "            \n",
    "            result = self.heteroconv(block, (src_features, dst_features))\n",
    "            return result['user'], result['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCRating(nn.Module):\n",
    "    def __init__(self, num_users, num_items, hidden_dims, num_ratings, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, hidden_dims)  \n",
    "        self.item_embeddings = nn.Embedding(num_items, hidden_dims)\n",
    "      \n",
    "        self.U_age = nn.Embedding(userAlterNum, hidden_dims)\n",
    "        self.U_gender = nn.Embedding(userGeschlechtNum, hidden_dims)\n",
    "        self.U_occupation = nn.Embedding(userBerufNum, hidden_dims)\n",
    "        self.U_genres = nn.Linear(moviesTypenNum, hidden_dims)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "   \n",
    "            GCMCLayer(hidden_dims, num_ratings) for _ in range(num_layers)]) \n",
    "     \n",
    "        self.W_u = nn.Linear(hidden_dims, hidden_dims\n",
    "        self.W_v = nn.Linear(hidden_dims, hidden_dims)\n",
    "        \n",
    "    def forward(self, blocks):\n",
    "      \n",
    "        user_embeddings = self.user_embeddings(blocks[0].srcnodes['user'].data[dgl.NID])\n",
    "        item_embeddings = self.item_embeddings(blocks[0].srcnodes['item'].data[dgl.NID])\n",
    "        \n",
    "     \n",
    "        user_embeddings = user_embeddings + self.U_age(blocks[0].srcnodes['user'].data['alter']) \n",
    "        user_embeddings = user_embeddings + self.U_gender(blocks[0].srcnodes['user'].data['geschlecht'])\n",
    "        user_embeddings = user_embeddings + self.U_occupation(blocks[0].srcnodes['user'].data['beruf'])\n",
    "        item_embeddings = item_embeddings + self.U_genres(blocks[0].srcnodes['item'].data['filmTyp'])\n",
    "        \n",
    "     \n",
    "        for block, layer in zip(blocks, self.layers):\n",
    "\n",
    "            user_embeddings, item_embeddings = layer(block, user_embeddings, item_embeddings) \n",
    "        \n",
    "        \n",
    "        z_u = self.W_u(user_embeddings) \n",
    "        z_v = self.W_v(item_embeddings)\n",
    "        \n",
    "        return z_u, z_v \n",
    "        \n",
    "    def compute_score(self, pair_graph, z_u, z_v):\n",
    "        with pair_graph.local_scope():\n",
    "          \n",
    "            pair_graph.nodes['user'].data['h'] = z_u \n",
    "            pair_graph.nodes['item'].data['h'] = z_v\n",
    "            \n",
    "  \n",
    "            pair_graph.apply_edges(fn.u_dot_v('h', 'h', 'r')) \n",
    "            \n",
    "            return pair_graph.edata['r'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def trainingLoop(NUM_LAYERS, BATCH_SIZE, NUM_EPOCHS, HIDDEN_DIMS, NUM_RATINGS, printing = True):\n",
    "    sampler = MinibatchSampler(graph, NUM_LAYERS) \n",
    "    \n",
    "  \n",
    "    train_dataloader = DataLoader(tensorTrainset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=True)\n",
    "    test_dataloader = DataLoader(tensorTestset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=False)\n",
    "        \n",
    "\n",
    "    model = GCMCRating(graph.number_of_nodes('user'), graph.number_of_nodes('item'), HIDDEN_DIMS, NUM_RATINGS, NUM_LAYERS) \n",
    "    \n",
    "   \n",
    "    opt = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "    \n",
    "    rmse = []\n",
    "    \n",
    "    for i in range(NUM_EPOCHS):\n",
    "        \n",
    "        model.train() \n",
    "       \n",
    "        with tqdm.tqdm(train_dataloader) as t: \n",
    "            for pair_graph, blocks in t:\n",
    "                user_emb, item_emb = model(blocks)\n",
    "                prediction = model.compute_score(pair_graph, user_emb, item_emb)\n",
    "                loss = ((prediction - pair_graph.edata['rating']) ** 2).mean()\n",
    "                opt.zero_grad() \n",
    "                loss.backward() \n",
    "                opt.step() \n",
    "\n",
    "        model.eval() \n",
    "    \n",
    "        with tqdm.tqdm(test_dataloader) as t: \n",
    "            with torch.no_grad():\n",
    "                predictions = []\n",
    "                ratings = []\n",
    "                for pair_graph, blocks in t:\n",
    "                    \n",
    "                    user_emb, item_emb = model(blocks) \n",
    "            \n",
    "                    prediction = model.compute_score(pair_graph, user_emb, item_emb) \n",
    "                    predictions.append(prediction) \n",
    "                    ratings.append(pair_graph.edata['rating']) \n",
    "\n",
    "                predictions = torch.cat(predictions, 0)\n",
    "                ratings = torch.cat(ratings, 0)\n",
    "        \n",
    "       \n",
    "        if printing:\n",
    "            print('RMSE:', mean_squared_error(predictions, ratings, squared=True).item() , ' - Nach',i+1,'. Epoch:')\n",
    "        \n",
    "        rmse.append(mean_squared_error(predictions, ratings, squared=True).item())\n",
    "    \n",
    " \n",
    "    if printing:\n",
    "        print('\\n\\nEvaluation for the following hyper parameters: \\n',\n",
    "              'NUM_LAYERS','=', NUM_LAYERS, '\\n',\n",
    "              'BATCH_SIZE','=', BATCH_SIZE, '\\n',\n",
    "              'NUM_EPOCHS','=', NUM_EPOCHS, '\\n',\n",
    "              'HIDDEN_DIMS','=', HIDDEN_DIMS, '\\n') \n",
    "        print('Finale RMSE:', mean_squared_error(predictions, ratings, squared=True).item())\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_LAYERS = 1 \n",
    "BATCH_SIZE = 400 \n",
    "NUM_EPOCHS = 15 \n",
    "HIDDEN_DIMS = 4 \n",
    "NUM_RATINGS = len(set(trainset['rating'])) \n",
    "\n",
    "rmse = trainingLoop(NUM_LAYERS, BATCH_SIZE, NUM_EPOCHS, HIDDEN_DIMS, NUM_RATINGS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [1,2] \n",
    "batchsizes = [400, 600, 800] \n",
    "hiddendims = [4, 6, 8] \n",
    "NUM_EPOCHS = 15\n",
    "NUM_RATINGS = len(set(trainset['rating']))\n",
    "\n",
    "evalDf = pd.DataFrame()\n",
    "\n",
    "for layer in layers:\n",
    "    for batchsize in batchsizes:\n",
    "        for hiddendim in hiddendims:\n",
    "           \n",
    "            start = timer() \n",
    "            \n",
    "            \n",
    "            rmse = trainingLoop(layer, batchsize, NUM_EPOCHS, hiddendim, NUM_RATINGS, printing = False)\n",
    "            \n",
    "            \n",
    "            end = timer() \n",
    "            timerSeconds = timedelta(seconds=end-start).total_seconds() \n",
    "            time = math.ceil(timerSeconds*10)/10 \n",
    "            \n",
    "     \n",
    "            evalDf = evalDf.append([{'Ebenen' : layer,'Batchgroesse' : batchsize,\n",
    "                                     'Hiddendims' : hiddendim,'Epochs' : NUM_EPOCHS,\n",
    "                                     'RMSE' : rmse, 'Zeit (s)' : time}], ignore_index=True)\n",
    "evalDf.to_csv(r'MovieLens+Feature-100k-10.csv')\n",
    "\n",
    "   \n",
    "bestRMSE = min(evalDf['RMSE']) # ermittle Zeile\n",
    "print('Lowest RMSE value with the following hyper parameters: \\n', evalDf.loc[[zeile]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
